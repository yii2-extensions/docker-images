#==============================================================================
# Rate Limiting and Traffic Control Configuration
# DDoS protection and abuse prevention
#==============================================================================

#------------------------------------------------------------------------------
# Connection Limits
#------------------------------------------------------------------------------
# Limit simultaneous connections per IP
<IfModule mod_limitipconn.c>
    # Maximum connections per IP
    MaxConnPerIP 20

    # Exclude local connections
    NoIPLimit 127.0.0.1
    NoIPLimit ::1
    NoIPLimit 10.0.0.0/8
    NoIPLimit 192.168.0.0/16

    # Custom error message
    IPCountLimit "Too many connections from your IP address"
</IfModule>

#------------------------------------------------------------------------------
# Request Rate Limiting with mod_rewrite
#------------------------------------------------------------------------------
<IfModule mod_rewrite.c>
    RewriteEngine On

    # Skip rate limiting for local requests
    RewriteCond %{REMOTE_ADDR} !^127\.0\.0\.1$
    RewriteCond %{REMOTE_ADDR} !^::1$
    RewriteCond %{REMOTE_ADDR} !^10\.
    RewriteCond %{REMOTE_ADDR} !^192\.168\.

    # Skip rate limiting for specific paths
    RewriteCond %{REQUEST_URI} !^/(health|status|ping)
    RewriteCond %{REQUEST_URI} !^/(assets|static|css|js|images)/

    # Rate limiting logic would go here
    # (This is a simplified example - production systems should use dedicated modules)
</IfModule>

#------------------------------------------------------------------------------
# User-Agent Based Filtering
#------------------------------------------------------------------------------
<IfModule mod_rewrite.c>
    RewriteEngine On

    # Block requests with no User-Agent
    RewriteCond %{HTTP_USER_AGENT} ^$
    RewriteCond %{REQUEST_URI} !^/(health|status|api/v1/health)
    RewriteRule .* - [F,L]

    # Block known malicious user agents
    RewriteCond %{HTTP_USER_AGENT} "(?i)(libwww-perl|python-urllib|python-requests|curl|wget|java|go-http-client)" [OR]
    RewriteCond %{HTTP_USER_AGENT} "(?i)(bot|crawler|spider|scraper)" [OR]
    RewriteCond %{HTTP_USER_AGENT} "(?i)(scanner|checker|monitor)" [OR]
    RewriteCond %{HTTP_USER_AGENT} "(?i)(nikto|nessus|openvas|nmap|masscan)" [OR]
    RewriteCond %{HTTP_USER_AGENT} "(?i)(sqlmap|havij|pangolin|w3af)" [OR]
    RewriteCond %{HTTP_USER_AGENT} "(?i)(acunetix|appscan|burp|ZAP|proxy)"
    RewriteCond %{REQUEST_URI} !^/(robots\.txt|favicon\.ico)
    RewriteRule .* - [F,L]

    # Allow legitimate bots (uncomment specific ones you want to allow)
    # RewriteCond %{HTTP_USER_AGENT} "(?i)googlebot"
    # RewriteRule .* - [S=10]
    # RewriteCond %{HTTP_USER_AGENT} "(?i)bingbot"
    # RewriteRule .* - [S=10]
</IfModule>

# vim: syntax=apache ts=4 sw=4 sts=4 sr noet
